{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "e3j7XEEzxQBz",
        "FjYTctVxxMqa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & Configs"
      ],
      "metadata": {
        "id": "Apq3UGkiKoPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6db0-jgRfQO",
        "outputId": "a729903c-e1e7-4daa-e3c2-cca915e0c619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "finetune_dataset_path = \"/content/drive/My Drive/synthetic_dataset/sales_dataset/finetune_dataset.csv\"\n",
        "finetune_dataset_df = pd.read_csv(finetune_dataset_path)"
      ],
      "metadata": {
        "id": "9ywxuv7JRtWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset Used To Generate Baseline Responses"
      ],
      "metadata": {
        "id": "oiAbdSe7KuHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 7"
      ],
      "metadata": {
        "id": "5rgtqlRDUK8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_indexes = []"
      ],
      "metadata": {
        "id": "9zSmrP9tXnQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_tones = finetune_dataset_df[\"post_tone\"].unique()"
      ],
      "metadata": {
        "id": "bFfabCPRSVWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tone in post_tones:\n",
        "  subset_df = finetune_dataset_df[finetune_dataset_df[\"post_tone\"] == tone]\n",
        "  subset_random = subset_df.sample(5, random_state = random_state).index\n",
        "  baseline_indexes.extend(subset_random)"
      ],
      "metadata": {
        "id": "pPLcRcq8SjKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_lengths = finetune_dataset_df[\"post_length\"].unique()"
      ],
      "metadata": {
        "id": "0Myt9mO3V6OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for length in post_lengths:\n",
        "  subset_df = finetune_dataset_df[finetune_dataset_df[\"post_length\"] == length]\n",
        "  subset_random = subset_df.sample(5, random_state = random_state).index\n",
        "  baseline_indexes.extend(subset_random)"
      ],
      "metadata": {
        "id": "c7-SECedVvP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_types = finetune_dataset_df[\"post_type\"].unique()"
      ],
      "metadata": {
        "id": "bPaYswHYW5MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _type in post_types:\n",
        "  subset_df = finetune_dataset_df[finetune_dataset_df[\"post_type\"] == _type]\n",
        "  subset_random = subset_df.sample(5, random_state = random_state).index\n",
        "  baseline_indexes.extend(subset_random)"
      ],
      "metadata": {
        "id": "SZisjsbRW4JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_df = finetune_dataset_df.iloc[baseline_indexes].copy()"
      ],
      "metadata": {
        "id": "SmJBiSjgnrgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = finetune_dataset_df[\"system_prompt\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbQEasLrY7Ny",
        "outputId": "3aaade5f-6e9f-4d9b-bbcd-bc7ec1024127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an expert sales copywriting assistant for social media who understands the attention economy and modern digital advertisment.\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Llama 3 8b Instruct 4 Bit & Generate Baseline Responses"
      ],
      "metadata": {
        "id": "6Id_kG8_K71q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "A4YwMnQiaiDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5cV_58paXiK",
        "outputId": "8bd11aa8-242e-421e-8bc0-36df891664c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load & Process Baseline Prompts For Baseline Response Generation"
      ],
      "metadata": {
        "id": "e3j7XEEzxQBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_prompts = []\n",
        "prompt_lengths = []\n",
        "for user_prompt in baseline_df[\"user_prompt\"]:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True,\n",
        "    )\n",
        "\n",
        "    prompt_lengths.append(len(prompt))\n",
        "\n",
        "    #the apply_chat_template adds the <begin_of_text> special token.\n",
        "    #However, this token is generated again during inference causing the special token to appear twice. Therefore, we are stripping the <begin_of_text> token so there is no duplicate token.\n",
        "    batch_prompts.append(prompt[17:])\n"
      ],
      "metadata": {
        "id": "GPJW98sY_rjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Baseline Responses"
      ],
      "metadata": {
        "id": "VqA7m0R_LYvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(batch_prompts, return_tensors = \"pt\", padding = True).to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 500, use_cache = True)\n",
        "responses = tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "fEYhxBUbf0bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(responses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4K3VV0imfCh",
        "outputId": "7bc497ee-b1bd-410e-ed74-06a8e4289fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Baseline Responses To Remove Special Tokens"
      ],
      "metadata": {
        "id": "TuDyA8ImLb3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_completions = []\n",
        "for response in responses:\n",
        "\n",
        "\n",
        "  # Word to strip before\n",
        "  first_split = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
        "  first_split_offset = len(first_split)\n",
        "  # Find the position of the word\n",
        "  index_first_split = response.find(first_split)\n",
        "\n",
        "  if index_first_split != -1:\n",
        "      subset_response = response[index_first_split + first_split_offset:].strip()\n",
        "\n",
        "  second_split = \"<|eot_id|>\"\n",
        "\n",
        "  index_second_split = subset_response.find(second_split)\n",
        "\n",
        "  if index_second_split != -1:\n",
        "      subset_response = subset_response[:index_second_split].strip()\n",
        "\n",
        "  baseline_completions.append(subset_response)\n",
        "  #print(subset_response)\n",
        "  #print(\"\\n\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YvT8gVlhdQl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_df[\"completion\"] = baseline_completions"
      ],
      "metadata": {
        "id": "iDa6FuiqpR5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for completion in baseline_df[\"completion\"][:5]:\n",
        "  print(completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJhWsXJJpaiu",
        "outputId": "566696f1-c896-49b8-b2b8-728040174bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Discover the future of science education with VirtualLab Science Simulations! Unlike traditional textbooks, our simulations bring the lab to life, allowing students to conduct virtual experiments and explore complex concepts in a safe and engaging environment. Compare our simulations to traditional teaching methods and experience the difference for yourself! #EduFuture #VirtualLab #ScienceSimulations\"\n",
            "\"Take your audio experience to the next level with SoundSync Wireless Transmitter from PureSound Audio! As a trusted name in the industry since 2012, we've crafted a wireless transmitter that delivers superior sound quality and seamless connectivity for professionals and audiophiles alike. Say goodbye to tangled cords and hello to freedom with our reliable and durable wireless solution. Upgrade your audio setup today and experience the difference PureSound Audio brings to the table.\"\n",
            "\"Stay cool and comfortable all day, every day! Introducing our CoolDry T-Shirts, featuring advanced moisture-wicking technology that keeps you dry and focused on your fitness goals. Upgrade your workout wardrobe with FitLife Apparel's premium performance tees #FitLifeApparel #CoolDryTShirts #FitnessClothing #MoistureWicking\"\n",
            "\"Protect Your Vision with BioLife's VisionGuard Lutein! As a trusted provider of natural health products, BioLife Supplements is proud to introduce VisionGuard Lutein, a powerful lutein supplement designed to support eye health and reduce the risk of age-related macular degeneration. Try it today and see the difference for yourself! #BioLifeSupplements #VisionGuardLutein #EyeHealth\"\n",
            "\"Exciting News! BioLife Supplements is proud to introduce MemorySharp Ginkgo Biloba, a powerful supplement designed to support cognitive health and sharp memory. With its high-quality Ginkgo Biloba extract, this natural formula helps maintain focus, concentration, and mental clarity. Try it today and unlock your full potential! #BioLifeSupplements #MemorySharp #GinkgoBiloba #CognitiveHealth\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Baseline Dataset"
      ],
      "metadata": {
        "id": "LWqq3s5NLIck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_dataset_path = \"/content/drive/My Drive/synthetic_dataset/sales_dataset/baseline_dataset.csv\"\n",
        "baseline_df.to_csv(baseline_dataset_path, index = False)"
      ],
      "metadata": {
        "id": "BpiUk3rZpfgn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}