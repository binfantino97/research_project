loss_values,training_steps,time_to_finetune,finetune_count,baseline_count,raw_counts,finetune_over_baseline_ratio,experiment_name,subset_size,num_rows,total_runtime,finetune_steps
"[2.5913, 2.5859, 2.6281, 2.4284, 2.1194, 1.9431, 1.7473, 1.5605, 1.3023, 1.2379, 1.0701, 0.9759, 0.8432, 0.792, 0.7816, 0.7842, 0.6901, 0.6966, 0.6182, 0.7083, 0.6635, 0.5569, 0.5539, 0.5527, 0.5607, 0.4963, 0.5344, 0.5223, 0.49, 0.4496, 0.4556, 0.4596, 0.4629, 0.3662, 0.3446, 0.3941, 0.3682, 0.3746, 0.4232, 0.3353, 0.3086, 0.2951, 0.3331, 0.3145, 0.2594, 0.2661, 0.2503, 0.2247, 0.2493, 0.252, 0.2249, 0.2511, 0.2294, 0.2341, 0.2419, 0.1507, 0.154, 0.196, 0.1542, 0.1722, 0.1661, 0.1501, 0.1833, 0.1308, 0.1525, 0.1647, 0.1056, 0.1103, 0.1025, 0.1143, 0.0953, 0.0991, 0.1033, 0.1046, 0.1003, 0.1089, 0.0927, 0.0725, 0.0626, 0.0692, 0.0757, 0.0605, 0.0696, 0.0585, 0.0613, 0.0672, 0.0635, 0.0629, 0.0529, 0.0457, 0.0548, 0.0509, 0.0483, 0.0536, 0.0483, 0.0501, 0.0442, 0.0531, 0.0497, 0.0405, 0.0391, 0.0423, 0.0493, 0.0489, 0.0359, 0.0406, 0.0399, 0.0431, 0.0393, 0.0404, 0.0326, 0.0339, 0.0371, 0.0366, 0.034, 0.0321, 0.0335, 0.0409, 0.034, 0.0363, 0.0421, 0.0319, 0.03, 0.035, 0.0319, 0.0313, 0.0347, 0.0313, 0.0322, 0.034, 0.0305, 0.0312, 0.0295, 0.0325, 0.0308, 0.0289, 0.031, 0.0335, 0.0305, 0.0285, 0.0278, 0.0321, 0.0323, 0.0324, 0.0271, 0.0309, 0.0276, 0.032, 0.0317, 0.0308]","[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]",279.24,79,14,"{'Finetune completion': 79, 'Baseline completion': 14, 'Finetune completion[/START_PICK][START_EXPLANATION]I chose Completion 2 as the better post because it effectively communicates the benefits of MemorySharp Ginkgo Biloba while maintaining a professional tone. The post starts with a attention-grabbing headline, clearly states the product\'s purpose, and highlights its natural ingredients and benefits. The call-to-action (""Try it today and experience the power of natural cognition support!"") is more compelling and encourages the audience to take action. Additionally, the hashtags (#NaturalHealth #CognitiveSupport) are more relevant and targeted to the product\'s niche. Overall, Completion 2 better balances brevity, clarity, and emotional appeal, making it a more effective sales post.[/START_EXPLANATION]': 1, ""'Baseline completion'"": 1}",5.642857142857143,0.5%_finetune_data_150_finetune_steps,0.005,88,1206.39,150
